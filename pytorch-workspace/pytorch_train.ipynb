{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--num_classes'], dest='num_classes', nargs=None, const=None, default=99891, type=<type 'int'>, choices=None, help='number of classes (default: 99891)', metavar='N')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Light CNN Training')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='LightCNN')\n",
    "parser.add_argument('--cuda', '-c', default=True)\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 16)')\n",
    "parser.add_argument('--epochs', default=80, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=100, type=int,\n",
    "                    metavar='N', help='print frequency (default: 100)')\n",
    "parser.add_argument('--model', default='', type=str, metavar='Model',\n",
    "                    help='model type: LightCNN-9, LightCNN-29, LightCNN-29v2')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--root_path', default='', type=str, metavar='PATH',\n",
    "                    help='path to root path of images (default: none)')\n",
    "parser.add_argument('--train_list', default='', type=str, metavar='PATH',\n",
    "                    help='path to training list (default: none)')\n",
    "parser.add_argument('--val_list', default='', type=str, metavar='PATH',\n",
    "                    help='path to validation list (default: none)')\n",
    "parser.add_argument('--save_path', default='', type=str, metavar='PATH',\n",
    "                    help='path to save checkpoint (default: none)')\n",
    "parser.add_argument('--num_classes', default=99891, type=int,\n",
    "                    metavar='N', help='number of classes (default: 99891)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--arch ARCH] [--cuda CUDA] [-j N]\n",
      "                             [--epochs N] [--start-epoch N] [-b N] [--lr LR]\n",
      "                             [--momentum M] [--weight-decay W]\n",
      "                             [--print-freq N] [--model Model] [--resume PATH]\n",
      "                             [--root_path PATH] [--train_list PATH]\n",
      "                             [--val_list PATH] [--save_path PATH]\n",
      "                             [--num_classes N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1001/jupyter/kernel-8451005d-4118-46cd-87e9-d1355018133e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from nets.light_cnn import LightCNN_9Layers\n",
    "\n",
    "networks_map = {'LightCNN-9': LightCNN_9Layers}\n",
    "\n",
    "def get_network_fn(model_name, num_classes, weight_decay=0):\n",
    "    if model_name not in networks_map:\n",
    "        raise ValueError('Name of network unknown %s' % model_name)\n",
    "    func = networks_map[model_name]\n",
    "    return func(num_classes=num_classes)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    global args\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    # Select the network #\n",
    "    ######################\n",
    "    \n",
    "    model = get_network_fn(model_name='LightCNN-9', num_classes=10572, weight_decay=0)\n",
    "    print(model)\n",
    "\n",
    "    ########################################\n",
    "    # Configure the optimization procedure #\n",
    "    ########################################\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum,\n",
    "                               weight_decay=args.weight_decay)\n",
    "\n",
    "    ########################################\n",
    "    # Optionally resume from a checkpoint  #\n",
    "    ########################################\n",
    "    \n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    ################\n",
    "    # Data loader  #\n",
    "    ################\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ImageList(root=args.root_path, fileList=args.train_list, \n",
    "            transform=transforms.Compose([ \n",
    "                transforms.Resize(size=(args.img_size, args.img_size)),\n",
    "                transforms.RandomCrop(args.crop_size),\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ImageList(root=args.root_path, fileList=args.val_list, \n",
    "            transform=transforms.Compose([ \n",
    "                transforms.Resize(size=(args.img_size, args.img_size)),\n",
    "                transforms.CenterCrop(args.crop_size),\n",
    "                transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)   \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    # Define loss function #\n",
    "    ########################\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if args.cuda:\n",
    "        criterion.cuda()\n",
    "        \n",
    "        \n",
    "    ######################\n",
    "    # Run, Forrest Run!  #\n",
    "    ######################\n",
    "    \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        save_name = args.save_path + 'lightCNN_' + str(epoch+1) + '_checkpoint.pth.tar'\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'prec1': prec1,\n",
    "        }, save_name)\n",
    "\n",
    "        \n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time  = AverageMeter()\n",
    "    losses     = AverageMeter()\n",
    "    top1       = AverageMeter()\n",
    "    top5       = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input      = input.cuda()\n",
    "        target     = target.cuda()\n",
    "        input_var  = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output, _ = model(input_var)\n",
    "        loss   = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses     = AverageMeter()\n",
    "    top1       = AverageMeter()\n",
    "    top5       = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        input      = input.cuda()\n",
    "        target     = target.cuda()\n",
    "        input_var  = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output, _ = model(input_var)\n",
    "        loss   = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "\n",
    "    print('\\nTest set: Average loss: {}, Accuracy: ({})\\n'.format(losses.avg, top1.avg))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val   = 0\n",
    "        self.avg   = 0\n",
    "        self.sum   = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val   = val\n",
    "        self.sum   += val * n\n",
    "        self.count += n\n",
    "        self.avg   = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    scale = 0.457305051927326\n",
    "    step  = 10\n",
    "    lr = args.lr * (scale ** (epoch // step))\n",
    "    print('lr: {}'.format(lr))\n",
    "    if (epoch != 0) & (epoch % step == 0):\n",
    "        print('Change lr')\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * scale\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred    = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
