{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/__init__.py:1173: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from nets.light_cnn import LightCNN_9Layers\n",
    "from nets.deepid import *\n",
    "from nets.net_sphere import *\n",
    "from nets.vgg import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis_square(data):\n",
    "    \"\"\"Take an array of shape (n, height, width) or (n, height, width, 3)\n",
    "       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\"\"\"\n",
    "    \n",
    "    # normalize data for display\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    \n",
    "    \n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = (((0, n ** 2 - data.shape[0]),\n",
    "               (0, 1), (0, 1))                 # add some space between filters\n",
    "               + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=1)  # pad with ones (white)\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    return data\n",
    "    #plt.imshow(data); \n",
    "    #plt.axis('off')\n",
    "    \n",
    "    \n",
    "    \n",
    "networks_map = {'LightCNN-9': LightCNN_9Layers,\n",
    "\t\t'DeepID_256' : DeepID_256,\n",
    "               'DeepID_256_gray' : DeepID_256_gray,\n",
    "               'DeepID_128_gray' : DeepID_128_gray,\n",
    "               'sphere20' : sphere20,\n",
    "               'vgg11' : vgg11}\n",
    "\n",
    "def get_network_fn(model_name, num_classes, weight_decay=0):\n",
    "    if model_name not in networks_map:\n",
    "        raise ValueError('Name of network unknown %s' % model_name)\n",
    "    func = networks_map[model_name]\n",
    "    return func(num_classes=num_classes)\n",
    "\n",
    "\n",
    "    \n",
    "cudnn.benchmark = True\n",
    "    \n",
    "resume = True\n",
    "    \n",
    "\n",
    "    \n",
    "model = get_network_fn(model_name='sphere20', num_classes=10572, weight_decay=0)\n",
    "\n",
    "    \n",
    "#model.eval()\n",
    "   \n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "\n",
    "\n",
    "if resume:\n",
    "    checkpoint = torch.load('/data/zeng/pytorch_model/lightCNN_18_checkpoint.pth.tar')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "count     = 0\n",
    "input     = torch.zeros(1, 1, 256, 256)\n",
    "    \n",
    "\n",
    "img   = cv2.imread('256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#img   = cv2.resize(img, (128,128))\n",
    "img   = np.reshape(img, (256, 256, 1))\n",
    "img   = transform(img)\n",
    "input[0,:,:,:] = img\n",
    "\n",
    "     \n",
    "nput = input.cuda()\n",
    "input_var   = torch.autograd.Variable(input, volatile=True)\n",
    "_, features, conv1_map = model(input_var)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 7, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model_dict['module.conv1_1.weight']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = x.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 7, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.squeeze(x)\n",
    "x.shape\n",
    "#vis_square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = vis_square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 7, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = vis_square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39445651,  0.32021371,  0.27811751, ...,  0.32452577,\n",
       "         0.32295936,  1.        ],\n",
       "       [ 0.26429904,  0.20403926,  0.15999581, ...,  0.3057771 ,\n",
       "         0.30058306,  1.        ],\n",
       "       [ 0.3303065 ,  0.27075404,  0.2326407 , ...,  0.27441439,\n",
       "         0.26661143,  1.        ],\n",
       "       ..., \n",
       "       [ 0.41551644,  0.406591  ,  0.39262244, ...,  0.39546499,\n",
       "         0.39559203,  1.        ],\n",
       "       [ 0.43560123,  0.43309858,  0.43345582, ...,  0.39556533,\n",
       "         0.39559284,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
